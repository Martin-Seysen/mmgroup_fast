/** @file mm_axis3_case2B.c

Deals with axes of axis type 2A when the cooresponding baby axis is known.

*/

#include <stdlib.h>
#include <stdint.h>
#include "mat24_functions.h"
#define MMGROUP_GENERATORS_INTERN
#include "mmgroup_generators.h"
#include "clifford12.h"
#include "mm_op_fast.h"
#include "mm_op_fast_intern.h"
#include "mm_op_sub.h"   


//  %%GEN h
/// @cond DO_NOT_DOCUMENT 
//  %%GEN c





/**********************************************************************
* Tables for dealing with case 2B
**********************************************************************/

/// @cond DO_NOT_DOCUMENT 

/*
The intersection of the Leech lattice with the subspace 
of \f$\mathbb{r}^{24}\f$ spanned by the first eight unit vectors
is an 8-dimensional lattice of shape \f$\sqrt{2} E_8\f$.
Let  E_8 be the 8-dimensional subspace of the Leech lattice mod 2
spanned by that lattice \f$\sqrt{2} E_8\f$.

Let E8_BASIS be a fixed basis of the subspace E_8 given by
[0x600, 0x500, 0x700, 0x40f, 0x8f, 0x4f, 0x800000, 0x80f00f]
in *Leech lattice encoding*.

Then TABLE_TYPE2 the list of all 8-bit vectors b such that the
vector b * E8_BASIS is of type 2.

The order of the type-2 vectors in that table is:

   Cocode([i,j]),             0 <= j < i < 8;

   Cocode([i,j]) + Omega,     0 <= j < i < 8;

   Suboctad([0,1,...,7], k),  0 <= k < 64;

Here the pairs (i,j) are traversed in lexicographic order.
*/
static uint32_t TABLE_TYPE2[120] =  {
  // %%TABLE MM_TABLE_CASE2B_BASIS_TYPE2BASIS, uint8
};

/* Auxiliary table for function ``load_2B_baby_A``

In that function we must compute matrix products ``v_k^T * A * v_k``
(mod 3), for a symmetric 8 times 8 matrix ``A`` and 64 different
vectors ``v_k`` with entries +1 and -1, in a certain order. Summing up
the terms of these products for the off-diagonal parts of matrix A
is expensive. Put c(i,j,k) = v_k[i] * v_k[j], 0 <= j < i < 8, 
0 <= k < . When traversing these pairs (i,j) in lexicographic order,
then TABLE_AUX_E8[n] correponds to the n-th pair (i,j). The entry
TABLE_AUX_E8[n][k] is equal to M(c(i,j,k)) + 16 * M(c(i,j,k+32)),
with M(x) = 0 if x = 1, and M(x) = 3 if x = -1.
*/
static mmv_fast_row32_type TABLE_AUX_E8[28] =  {
  // %%TABLE MM_TABLE_CASE2B_BASIS_TABLE_AUX_E8
};

/* We have A_CONST[i][j] = i mod 3 for 0 <= i <4, 0 <= j < 32 */
static mmv_fast_row32_type A_CONST[4] = {
   // %%TABLE [[[(i % 3)] * 32] for i in range(4)]
};


/* We have A_MOD3[i] = i mod 3 for 0 <= i < 32 */
static uint8_t A_MOD3[32] = {
   // %%TABLE [(i % 3) for i in range(32)]
};


/**
@brief Table for hash function, used for multipliction with Hadamard Matrix

Let ``h`` be a hash function that maps a pair (a, b) of integers to an
integer k. Here a and b are given as integers mod 3, and the functional
value k satifies 0 < k < 128.

Let E_8 is be the standard E_8 sublattice of the Leech lattice as above.
Then a 2A axis provides some information about all type2-vectors in 
the sublattice E_8, but no direct information about any type-4 vector
in e_0. However, we need information about these type-4 vectors in order
to partition them in a reasoable way.
 
More specifially, for a type-3 vector ``v`` in an e_8 sublattice, and an
axis X, we obtain the matrix product ``a = a(v, X) = v_k^T * A * v_k``
(mod 3) from the part 'A' of the axis, and a information ``b = B(v, X)``
as the co-ordinate of the part 98280_x of the axis corresponding to 
vector ``v``. (In order to determine the sign of ``b``, we actually need
a pair of axes, with the other axis X_E of axis type '2B', such that the
corrsponding 2A involution fixes the standard sublattice E_8). 
  
For any axis X we may compute hash values H(v,X) = h(a(v,X), b(v,X)),
for all type-2 vectors v in E_8. Here h is a function mapping a
pair(a,b)  of integers (given mod 3) to an integer 0 < h(a,b) < 128.
We put H(v,X) = 0 for the vectors in E_8 that are not of type 2. Then
the mapping E_8 -> N_128 given by v |-> H(v, X) is invariant under any
mapping fixing both axes, X and X_E. Here N_128 is the set of
integers modulo 128.

Let E8_BASIS be the basis of E_8 defined above. We order the elements
of E_8 by the bit vectors of their co-ordinates with respect to that
basis, where bit vectors are intepreted as binary digits of integers.
This way a mapping E_8 -> N_128 is given as a vector w of length 256.
More precisely, w is an element of the module N_128^{256}.     

Let H256 be the standard 256 times 256 Hadamard matrix with entries
+1 and -1. By standard properies of harmonic analysis in GF_2^8 we see
that right multiplication of a vector w in N_128^{256} by the Hadamard
matrix H256 transforms w into a vector in the dual module of
N_128^{256}. Since E_8 has a natural orthogonal structure, the module
N_128^{256} may be identified with its dual. So we may consider
w * H256 also as an element of N_128^{256}. Especially, w *H256 may
contain nonzero entries at the co-ordinates corresponding to the
type-4 vectors in E_8. This information may be used to partition the
type-4 vectors in E_8.

TABLE_COEFF[4*b + a], 0 <= a, b < 4 contains the value h(a % 3, b % 3).
*/
static uint8_t TABLE_COEFF[16] =  {
  // %%TABLE MM_TABLE_CASE2B_BASIS_COEFF
};



/// @endcond 




/**********************************************************************
* Load data for part A into a structure of type mm_axis3_fast_load
**********************************************************************/


/// @cond DO_NOT_DOCUMENT 



/**  
  Load values of type-2 vector in E_8 lattice.

  Let ``pb`` point to a vector of entries in part 'A' of the Griess
  algebra mod 3. Here entry ('A', i, j) is encoded in ``pa[32*i+j]``,
  0 < i, j, 24,  as usual.

  The table ``TABLE_TYPE2`` defines an order of the 120 type-2 vectors
  in the sublattice E_8 of the Leech lattice defined  in the
  description of that table.

  the function computes the values ``v^T * A * v`` (mod 3), where ``v``
  runs through the 120 type-2 vectors in e_8 in the order given 
  by ``TABLE_TYPE2``, and 'A' is the 24 times 24 matrix described
  above. The list of these 120 values is stored in the array referred
  by ``p2``.         
*/
static inline void load_2B_baby_A(uint8_t *pb, uint8_t *p2)
{
     uint8_t diag[8];
     uint_fast32_t i, j, k = 0, d = 0;
     mmv_fast_row32_type e8l, e8h;
     for (i = j = 0; i < 8; ++i, j += 33) d += (diag[i] = pb[j] & 3);
     e8h = e8l = A_CONST[d % 3];
     for (i = 0; i < 8; ++i) {
         uint8_t a = diag[i];
         for (j = 0; j < i; ++j) {
             uint8_t ab = a + diag[j], x = pb[j] & 3;
             p2[k] = A_MOD3[ab + x];
             p2[k + 28] = A_MOD3[ab + (x ^ 3)];
             e8l.v32[0] += A_CONST[x].v32[0] 
                        ^ (TABLE_AUX_E8[k].v32[0] & (uint8_t)3);
             e8h.v32[0] += A_CONST[x].v32[0] 
                        ^ (TABLE_AUX_E8[k].v32[0] >> 4);
             ++k;
         }
         pb += 32;
     }
     e8l.v32[0] = (e8l.v32[0] & 15) + (e8l.v32[0] >> 4);
     e8h.v32[0] = (e8h.v32[0] & 15) + (e8h.v32[0] >> 4);
     for (i = 0; i < 32; ++i) {
         p2[i + 56] = A_MOD3[e8l.b[i]];
         p2[i + 56 + 32] = A_MOD3[e8h.b[i]];
     }
}


/// @endcond 


/**********************************************************************
* Load vector data A into a structure of type mm_axis3_fast_load
**********************************************************************/

/// @cond DO_NOT_DOCUMENT 



/**  
  Compute mapping from type-2 vectors of sublattice E_8 to integer

  In this function we assume the following conditions on input.

  A transformed axis X' = X * g  has been loaded to array ``B`` in
  the structure referred by ``pA`. Here ``g`` must be an element
  of the group \f$G_{x0}\f$. The component ``pa->p_source`` points
  to a matrix containing four rows, with two of these rows containing
  axes. Row ``pa->sub_row_source`` contains the axis ``X``.
  Row ``pa->row_source`` contains a axis ``X_E`` of axis type '2B',
  with ``X_E`` orthogonal to ``X``. The involution corresponding to
  the axis  ``X_E' = X_E * g`` is in \f$G_{x0}\f$ (since ``X_E'`` is
  also of axis type '2B') and that involution fixes the standard 
  subspace E_8 of the Leech lattice mod 2 as defined above.

  Let H(., .) be defined as avove.
  Then the function computes the vector H(v,X') for all type-2
  vectors ``v `` in E_8. Therefore we need part 'A' of the axis ``X'``
  (which is already present in our structure), and the co-ordinates of
  part 98280_x of axes ``X'`` and ``X_E'`` corresponding to the type-2
  vectors ``v`` in E_8. The easiest way to obtain the co-ordinate
  for ``v`` of ``X * g`` is to access the co-ordinate for ``v * g**-1``
  of ``X``, and similar for  ``X'``. Therefore we have to provide the
  group element ``g**-1`` or, alternatively, the images of the standard
  basis vectors of E_8 under the action of ``g**-1``. We povide the
  images of the basis vectors in expanded form in parameter ``v``, as
  defined in structure ``in info_6F_type`` in file mm_axis3_case6F.c . 
    
  We output the vector H(v,X') of length 256 in the array referred
  by ``p_res`` as an array of unsigned 8-bit integers. There is a
  special case, when the entries H(v,X') for all type-2 vectors are
  equal to h(0,0), with h(.,.) as above. In this case vector H(v,X')
  provides no useful information; and the function does not change
  the output array and returns 0. Otherwise (i.e. in the standard
  case) the function returns 1.
*/
static inline int32_t
load_2B_vect(mmv_fast_Amod3_type *pa, uint32_t v[2][16], mmv_fast_row32_type *p_res)
{
    uint8_t *p_baby_A = (uint8_t*)(pa->a + 24);
    union {
        uint8_t b[120];
        uint64_t u64[15];
    } va, vb;
    mmv_fast_type *padata = mm_axis3_fast_source_ptr(pa);
    if (padata == NULL) return -3;
    uint8_t *vector = padata->b;
    int32_t i;

    load_2B_baby_A(p_baby_A, va.b);   
    for (i = 0; i < 120; ++i) {
        #define leech_vect(i) (v[0][(i) & 15] ^ v[1][((i) >> 4) & 15])
        uint32_t ind_leech = leech_vect(TABLE_TYPE2[i]);
        uint32_t ind = mm_aux_index_leech2_to_intern_fast(ind_leech);
        vb.b[i] = vector[ind];
        #undef leech_vect
    }

    uint32_t sh = 2 * pa->row_source;
    uint32_t baby_sh = 2 * pa->sub_row_source;
    uint64_t err = 0x0202020202020202ULL, acc = 0;
    uint64_t MASK0 = TABLE_COEFF[0] * 0x0101010101010101ULL;

    for (i = 0; i < 15; ++i) {
        uint64_t x = (vb.u64[i] >> sh) & 0x0303030303030303ULL, mask;
        uint64_t baby_x = (vb.u64[i] >> baby_sh) & 0x0303030303030303ULL;
        err &= x + 0x0101010101010101ULL;
        mask = x & 0x0202020202020202ULL;
        x = baby_x ^ mask ^ (mask >> 1);
        va.u64[i] = (x << 2) | (va.u64[i] & 0x0303030303030303ULL);
    }
    if (err != 0x0202020202020202ULL) return -193;
    for (i = 0; i < 120 ; ++i) va.b[i] = TABLE_COEFF[va.b[i]];
    for (i = 0; i < 15; ++i)  acc |= va.u64[i] ^ MASK0;
    if (acc) {
        memset(p_res, 0, 256 * sizeof(uint8_t));
        for (i = 0; i < 120; ++i) p_res->b[TABLE_TYPE2[i]] = va.b[i];
        return 1;
    } 
    return 0;
}






/// @endcond 



/**********************************************************************
***********************************************************************
* Compute watermark function for type-4 vectors
***********************************************************************
**********************************************************************/

/**  
  @brief Yet to be documented!!!!!

  Returns 1 if any information can be obtained from hadamard transform,
  0 if not, and -1 in case of an error. 
*/
// %%EXPORT p
int32_t mm_axis3_fast_2B_load_baby(mmv_fast_Amod3_type *pa, uint32_t v[2][16])
{
    int32_t status = load_2B_vect(pa, v, pa->a + 32);
    if (status < 0) return status;
    if (status > 0) {
        memcpy(pa->a + 40, pa->a + 32, 256 * sizeof(uint8_t));
        mm_axis3_fast_hadamard256(pa->a + 32);
    }
    // Store basis of sublattice of Leech lattice in the slack for debugging
    uint32_t i, *p_slack = (uint32_t*)(pa->a + 24) + 6;
    for (i = 0; i < 4; ++i) {
        p_slack[8*i] = v[0][1<<i];
        p_slack[8*i + 32] = v[1][1<<i];
    }
    return status;
}


/**********************************************************************
***********************************************************************
* Compute a suitable type-4 vector in case with Hadamard matrix
***********************************************************************
**********************************************************************/

static uint8_t TABLE_TYPE4_INDEX[135] =  {
  // %%TABLE MM_TABLE_CASE2B_BASIS_TYPE4_INDEX
};

static uint8_t TABLE_TYPE4_COORD[135] =  {
  // %%TABLE MM_TABLE_CASE2B_BASIS_TYPE4_COORD
};



/**  
  @brief Yet to be documented!!!!!
*/
// %%EXPORT p
int32_t mm_axis3_fast_2B_compute_v4(mmv_fast_Amod3_type *pa, uint32_t v[2][16])
{
    uint8_t *wmark = (uint8_t*)(pa->a + 32);
    uint8_t *count = (uint8_t*)(pa->a + 40);
    uint32_t i, w_min = 255, count_min = 255;
    memset(count, 0xff, 128 * sizeof(uint8_t));
    for (i = 0; i < 135; ++i) {
        uint8_t w = wmark[TABLE_TYPE4_INDEX[i]] & 0x7f;
        ++count[w]; 
    }
    for (i = 0; i < 128; ++i) if (count[i] < count_min) {
        count_min = count[i];
        w_min = i;
    }
    count[i] = w_min;
    uint32_t v_min = 0xffffffffUL, v_found;
    for (i = 0; i < 135; ++i) {
        if (wmark[TABLE_TYPE4_INDEX[i]] == w_min) {
            uint8_t coord = TABLE_TYPE4_COORD[i];
            v_found = (v[0][coord & 15] ^ v[1][coord >> 4]) & 0xffffffUL;
            v_found |= gen_leech2_coarse_subtype_inline(v_found) << 24;
            if (v_found < v_min) v_min = v_found; 
        }
    }
    if (v_min == 0xffffffffUL) return -192;
    return (v_min & 0xffffffUL) + (2 << 25);
}



/**********************************************************************
***********************************************************************
* Compute a suitable type-4 vector in case without Hadamard matrix
***********************************************************************
**********************************************************************/

typedef struct {
    uint32_t tf[20];
    uint32_t len_tf;
    mmv_fast_Amod3_type *pa;
} s_2B2_type;
    



static inline int32_t map_second_octad(uint32_t o)
{
    uint32_t i, tet = 0, std_o_sub, syn;
    uint8_t pi[24], pi_in[7], xch, tmp;
    static uint8_t pi_out[7] = {8,9,10,11,12,0,4};
    mat24_vect_to_list(o, 3, pi_in);
    pi_in[3] = pi_in[0] ^ pi_in[1] ^ pi_in[2];  
    for (i = 0; i < 4; ++i) tet |= 1UL << pi_in[i];
    if (mat24_bw24(o) != 8) return -5;
    if (o & 0xff) return -6;
    if ((tet & o) != tet) return -7;
    std_o_sub = mat24_syndrome(tet, 0);
    if ((std_o_sub & 0xff) != std_o_sub) return -8;
    pi_in[4] = mat24_lsbit24(o & ~tet);
    pi_in[5] = mat24_lsbit24(0xff & std_o_sub);
    pi_in[6] = mat24_lsbit24(0xff & ~std_o_sub);
    for (i = 4; i < 7; ++i) tet |= 1UL << pi_in[i];
    syn = mat24_syndrome(tet, 24);
    if (syn & 0xff000000UL) return -9;
    if (mat24_bw24(tet & syn) != 1) return -10;
    xch = (uint8_t)mat24_lsbit24(tet & syn);
    for (i = 1; i < 4; ++i) if (pi_in[i] == xch) {
        tmp = pi_in[i]; pi_in[i] = pi_in[0]; pi_in[0] = tmp;
        break;
    }
    if (mat24_perm_from_heptads(pi_in, pi_out, pi) != 0) return -11;
    return MMGROUP_ATOM_TAG_P + mat24_perm_to_m24num(pi);
}



#define L_CAND 15

static uint32_t TABLE_E8_SUBSPACE_8_9[1 + L_CAND] =  {
  // %%TABLE MM_TABLE_CASE2B_E8_SUBSPACE_8_9
};


static inline
int32_t analyze_base_case_2A(s_2B2_type *s2, uint64_t v3, uint32_t weight)
{
    if (weight == 8) {
        uint32_t supp = (uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL);
        int32_t status = map_second_octad(supp);
        if (status < 0) return status;
        s2->tf[s2->len_tf] = (uint32_t)status;
        v3 = gen_leech3_op_vector_atom(v3, s2->tf[(s2->len_tf)++]);        
        uint32_t sign = mat24_def_parity12((uint32_t)(v3 & 0xf00));
        s2->tf[s2->len_tf] = MMGROUP_ATOM_TAG_L + 2 - sign;
        v3 = gen_leech3_op_vector_atom(v3,s2->tf[(s2->len_tf)++]);
        weight =  mat24_bw24((uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL));
    }

    uint8_t pi[24], pi_in[7];
    static uint8_t pi_out[7] = {0,1,2,3,4,8,9};
    uint32_t supp = (uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL);
    if (mat24_bw24(supp) != 2) return -2012;
    if (0xff & supp) return -2013;
    uint32_t t = mat24_intersect_octad_tetrad(0xff, supp);
    if (t & 0xff000000UL) return -2014;
    mat24_vect_to_list(0xff & t, 4, pi_in);
    mat24_vect_to_list(0xff & ~t, 1, pi_in+4);
    mat24_vect_to_list(supp, 2, pi_in+5);
    if (mat24_perm_from_heptads(pi_in, pi_out, pi)) return -2015;
    s2->tf[s2->len_tf] = MMGROUP_ATOM_TAG_P + mat24_perm_to_m24num(pi);
    v3 = gen_leech3_op_vector_atom(v3,s2->tf[(s2->len_tf)++]);
    supp = (uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL);
    if (supp != 0x300) return -2016;
    uint64_t sign = ((v3 >> 8) ^ (v3 >> 9) ^ 1) & 1;
    // if ``sign`` is nonzero then use the follwing atom in N_x0
    // to negate bits of v3 at positions 2*i, 0 <= i < 8.
    if (sign) {
        s2->tf[s2->len_tf] = 0x400002acUL; 
        v3 = gen_leech3_op_vector_atom(v3,s2->tf[(s2->len_tf)++]);
    }
    if (v3 & 0x200) v3 =  gen_leech3_neg(v3);
    if (gen_leech3_reduce(v3) != 0x200000100ULL) return -2017;

    uint32_t cand[L_CAND], v_min = 0xffffffff, i;
    mm_group_invert_word(s2->tf, s2->len_tf);
    if (mm_axis3_fast_transform_fix_leech2(TABLE_E8_SUBSPACE_8_9, s2->tf,
        s2->len_tf, cand, L_CAND) != L_CAND) return -2018;
    for (i = 0; i < L_CAND; ++i) {
        uint32_t v = cand[i] & 0xffffff;
        v += gen_leech2_coarse_subtype_inline(v) << 24;
        if (v < v_min) v_min = v;
    }
    if (v_min == 0xffffffff) return -2019;
    return ((v_min & 0xffffff) + (2UL << 25));
}

#undef L_CAND







static inline
int32_t analyze_base_case_2B_1(s_2B2_type *s2, uint32_t supp)
{
    mmv_fast_Amod3_type *pa = s2->pa;
    int32_t perm = map_second_octad(supp), i;
    if (perm < 0) return perm;
    s2->tf[s2->len_tf] = (uint32_t)perm;
    mm_axis3_fast_op_G_x0(pa, s2->tf + s2->len_tf, 1, 1);
    s2->len_tf += 1;
    {   // DEBUG!!
        mm_op_fast_word_A_mod_3(pa->a, s2->tf, s2->len_tf); 
        uint32_t *p_slack = (uint32_t*)(pa->a + 24) + 6;
        for (i = 0; i < s2->len_tf; ++i) p_slack[8*i] = s2->tf[i];
        for (; i < 24; ++i) p_slack[8*i] = 0;
    }

    uint32_t cand[8];
    mmv_fast_type *padata = mm_axis3_fast_source_ptr(pa);
    if (padata == NULL) return -3;
    uint8_t *b = padata->b;
    uint32_t sh0 = pa->row_source << 1;
    uint32_t sh8 = pa->sub_row_source << 1;
    uint32_t a_sign[2], acc = 2, e0, e8;    
    static uint32_t TABLE_E8_SUBSET_TRIO[8] =  {
       // %%TABLE MM_TABLE_CASE2B_E8_SUBSET_TRIO, uint32
    };

    mm_group_invert_word(s2->tf, s2->len_tf);
    memcpy(cand, TABLE_E8_SUBSET_TRIO, 8 * sizeof(uint32_t));
    if (gen_leech2_op_word_many(cand, 8, s2->tf, s2->len_tf)
        != s2->len_tf) return -2117;
    #define get_entry(index, shift, res) \
        res = b[mm_aux_index_leech2_to_intern_fast(index)] >> shift; \
        acc &= res + 1; \
        res ^= index >> 23;
    for (i = 0; i < 2; ++i) {
        get_entry(cand[4+i], sh0, e0);
        get_entry(cand[6+i], sh8, e8);
        a_sign[i] = e0 ^ e8;
    }
    for (i = 0; i < 4; ++i) {
        uint32_t n = (i != 0), sign = a_sign[n];
        uint32_t x = gen_leech2_mul(cand[i], cand[4+n]);
        get_entry(x, sh0, e0);
        x = gen_leech2_mul(cand[i], cand[6+n]); 
        get_entry(x, sh8, e8);
        sign ^= e0 ^ e8; 
        cand[i] = (cand[i] & 0xffffff) + ((sign & 2) << 23);
    }
    #undef vect
    if ((acc & 2) == 0) return -2118;
    
    uint32_t v_min = 0xffffffff, v0 = 0, v;
    static uint8_t GRAYCODE[15] = {0,1,0,2,0,1,0,3,0,1,0,2,0,1,0};
    for (i = 0; i < 15; ++i) {
        v0 ^= cand[GRAYCODE[i]];
        if (v0 & 0x1000000UL) continue;
        v = v0 & 0xffffffUL;
        v ^=  gen_leech2_coarse_subtype_inline(v) << 24;
        if (v < v_min) v_min = v;
    }
    if (v_min == 0xffffffff) return -2119;
    return ((v_min & 0xffffff) + (2UL << 25));
}






static inline
int32_t analyze_base_case_2B_2(s_2B2_type *s2, uint32_t supp1, uint32_t supp2)
{
    uint8_t pi[24], pi_in[6];
    static uint8_t pi_out[6] = {8,9,10,11,0,4};
    uint32_t t = mat24_intersect_octad_tetrad(0xff, supp1 | supp2);
    if (t & 0xff000000UL) return -3011;
    mat24_vect_to_list(supp1, 2, pi_in);
    mat24_vect_to_list(supp2, 2, pi_in + 2);
    if (pi_in[0] ^ pi_in[1] ^ pi_in[2] ^ pi_in[3]) return  -3012;
    pi_in[4] = mat24_lsbit24(0xff & t);
    pi_in[5] = mat24_lsbit24(0xff & ~t);
    if (mat24_perm_from_map(pi_in, pi_out, 6, pi) <= 0) return -3013;
    s2->tf[s2->len_tf] = MMGROUP_ATOM_TAG_P + mat24_perm_to_m24num(pi);
    mm_axis3_fast_op_G_x0(s2->pa, s2->tf + s2->len_tf, 1, 1);
    s2->len_tf += 1;
    mmv_fast_row32_type *p_row = s2->pa->a + 24;
    uint32_t sign = (p_row[8].b[9] ^ p_row[10].b[11]) & 1;
    s2->tf[s2->len_tf] = MMGROUP_ATOM_TAG_L + 2 - sign;
    mm_axis3_fast_op_G_x0(s2->pa, s2->tf + s2->len_tf, 1, 1);
    s2->len_tf += 1;
    return 0x40000000;
}




static int32_t inline analyze_basis(s_2B2_type *s2)
{
    mmv_fast_Amod3_type *pa = s2->pa;
    uint32_t i, supp, w, other, supp2;
    uint8_t *pd = (pa->a + 24 + 8)->b + 8;
    for (i = 8; i < 24; ++i, pd += 33) if ((*pd + 1) & 2) {
         uint64_t v3 = mm_axis3_fast_to_leech_mod3(pa, i + 24);
         supp = (uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL);
         w = mat24_bw24(supp);
         switch (w) {
             case 1:
                 supp = 0;
                 for (; i < 24; ++i, pd += 33) supp |= ((*pd + 1) & 2) << i;
                 return analyze_base_case_2B_1(s2, supp >> 1);
             case 2:
                 if (*pd & 1) return analyze_base_case_2A(s2, v3, 2);
                 other = mat24_lsbit24(supp & ~(1UL << i));
                 ++i; pd += 33;
                 for (; i < 24; ++i, pd += 33) {
                     if (i != other && (*pd + 1) & 2) {
                         v3 = mm_axis3_fast_to_leech_mod3(pa, i + 24);
                         supp2 = (uint32_t)((v3 ^ (v3 >> 24)) & 0xffffffUL);
                         return analyze_base_case_2B_2(s2, supp, supp2);
                     }
                 }
                 return -4001;
             case 8:
                 return analyze_base_case_2A(s2, v3, 8);
             default:
                 return -4002;
                   
         }  
    }
    return -4004;
}




/**  
  @brief Yet to be documented!!!!!
*/
// %%EXPORT p
int32_t mm_axis3_fast_2B2_compute_v4(mmv_fast_Amod3_type *pa, uint32_t basis[8])
{
     s_2B2_type s2;
     s2.pa = pa;
     s2.len_tf = 8;
     while (s2.len_tf && basis[s2.len_tf-1] == 0) --s2.len_tf;
     memcpy(s2.tf, basis, s2.len_tf * sizeof(uint32_t));
     mm_group_invert_word(s2.tf, s2.len_tf);
     uint32_t status = analyze_basis(&s2);
     if (status < 0) return status;
     if (status & 0x40000000) status = analyze_basis(&s2);
     return status;
}


/**********************************************************************
* end of C functions
**********************************************************************/



//  %%GEN h
/// @endcond 
//  %%GEN c

